{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "title: \"Clarity Tables\"\n",
        "jupyter: \"starr-oncology-data-lake-arpah\"\n",
        "execute:\n",
        "  echo: false\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "Below the list of the EPIC Clarity tables needed to assemble the CAP forms and the pathology reports. The table name contains the link for the full public description of the table including the columns of each one and the description of the columns. \n"
      ],
      "id": "d72ae77b"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| output: asis\n",
        "#| echo: false\n",
        "\n",
        "\n",
        "import requests\n",
        "from lxml import html\n",
        "from google.cloud import bigquery\n",
        "import pandas as pd\n",
        "import os\n",
        "from IPython.display import HTML\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "credentials_path = \"/home/rstudio/.config/gcloud/application_default_credentials.json\"\n",
        "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = credentials_path\n",
        "project_id = 'som-rit-phi-oncology-prod'\n",
        "os.environ[\"GOOGLE_CLOUD_PROJECT\"] = project_id\n",
        "dataset_id = 'oncology_cap_forms_phi_irb76049_aug2025'\n",
        "bq_client = bigquery.Client(project=project_id)\n",
        "base_url = \"https://open.epic.com/EHITables/GetTable/\"\n",
        "# XPath to extract text from\n",
        "xpath = \"/html/body/div[2]/div[2]/main/div[2]/table[2]/tbody/tr/td[2]/table/tbody/tr/td/text()\"\n",
        "#base_url = \"https://open.epic.com/EHITables/GetTable/ABN_DOCUMENT_ID.htm\"\n",
        "exclude_tables = ['cap_forms', 'shc_pathology_reports']\n",
        "\n",
        "def get_bigquery_table_names(project_id, dataset_id, exclude_tables=None):\n",
        "    \"\"\"\n",
        "    Get all table names from a BigQuery dataset\n",
        "    \n",
        "    Args:\n",
        "        project_id (str): The BigQuery project ID\n",
        "        dataset_id (str): The BigQuery dataset ID\n",
        "        exclude_tables (list): Optional list of table names to exclude\n",
        "    \n",
        "    Returns:\n",
        "        list: List of table names in the dataset\n",
        "    \"\"\"\n",
        "    if exclude_tables is None:\n",
        "        exclude_tables = []\n",
        "    \n",
        "    try:\n",
        "        # Get dataset reference\n",
        "        dataset_ref = bq_client.dataset(dataset_id, project=project_id)\n",
        "        \n",
        "        # List all tables in the dataset\n",
        "        tables = bq_client.list_tables(dataset_ref)\n",
        "        \n",
        "        # Extract table names, excluding any in the exclude list\n",
        "        table_names = [\n",
        "            table.table_id for table in tables \n",
        "            if table.table_id not in exclude_tables\n",
        "        ]\n",
        "        \n",
        "        return sorted(table_names)\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"Error retrieving table names: {e}\")\n",
        "        return []\n",
        "\n",
        "def extract_text_from_xpath(url, xpath):\n",
        "    \"\"\"\n",
        "    Fetch HTML from URL and extract text using the specified XPath\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Send GET request to the URL\n",
        "        response = requests.get(url)\n",
        "        response.raise_for_status()  # Raise an exception for bad status codes\n",
        "        \n",
        "        # Parse the HTML content\n",
        "        tree = html.fromstring(response.content)\n",
        "        \n",
        "        # Extract text using XPath\n",
        "        result = tree.xpath(xpath)\n",
        "        \n",
        "        if result:\n",
        "            # If result is a list, join the text elements\n",
        "            if isinstance(result, list):\n",
        "                return ' '.join(str(item).strip() for item in result if str(item).strip())\n",
        "            else:\n",
        "                return str(result).strip()\n",
        "        else:\n",
        "            return \"Description not available in public EPIC documentation\"\n",
        "            \n",
        "    except requests.RequestException as e:\n",
        "        return f\"Error fetching URL: {e}\"\n",
        "    except Exception as e:\n",
        "        return f\"Error parsing HTML or XPath: {e}\"\n",
        "\n",
        "\n",
        "\n",
        "table_names = get_bigquery_table_names(project_id, dataset_id, exclude_tables)\n",
        "\n",
        "descriptions = []\n",
        "urls = []\n",
        "for table in table_names:\n",
        "    url = f\"{base_url}{table.upper()}.htm\"\n",
        "    extracted_text = extract_text_from_xpath(url, xpath)\n",
        "    descriptions.append(extracted_text)\n",
        "    urls.append(url)\n",
        "\n",
        "df = pd.DataFrame({\n",
        "    'Table Name': table_names,\n",
        "    'Table Description': descriptions,\n",
        "    'URL': urls\n",
        "})\n",
        "\n",
        "# Convert DataFrame to HTML and display\n",
        "HTML(df.to_html(escape=False, table_id=\"df\", index=False, render_links=True))"
      ],
      "id": "a75f774c",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "starr-oncology-data-lake-arpah",
      "language": "python",
      "display_name": "starr-oncology-data-lake-arpah",
      "path": "/root/.local/share/jupyter/kernels/starr-oncology-data-lake-arpah"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}